{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем строить нейросеть для распознавания цифр. Это набор mnist.\n",
    "Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
    "y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#28*28\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "# нормализация\n",
    "x_train =x_train /255\n",
    "\n",
    "y_train = utils.to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем модель\n",
    "relu : f(x) = max(0,x)\n",
    "softmax - сумма всех выходных значений нейронов равна 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(800,input_dim = 784, activation =\"relu\"))\n",
    "model.add(Dense(10, activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компилируем модель\n",
    "loss категориальная перекресная энтропия (хорошо работает с несколькими классами)\n",
    "optimizer стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 636,010\n",
      "Trainable params: 636,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer =\"SGD\", metrics =[\"accuracy\"] )\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели\n",
    "0.2 идет на validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 1.4414 - acc: 0.6694 - val_loss: 0.8839 - val_acc: 0.8355\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.7367 - acc: 0.8451 - val_loss: 0.5812 - val_acc: 0.8734\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.5547 - acc: 0.8702 - val_loss: 0.4731 - val_acc: 0.8882\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.4750 - acc: 0.8817 - val_loss: 0.4183 - val_acc: 0.8948\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.4291 - acc: 0.8891 - val_loss: 0.3840 - val_acc: 0.9012\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.3986 - acc: 0.8949 - val_loss: 0.3609 - val_acc: 0.9067\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.3766 - acc: 0.8991 - val_loss: 0.3431 - val_acc: 0.9092\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3592 - acc: 0.9030 - val_loss: 0.3301 - val_acc: 0.9119\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3453 - acc: 0.9054 - val_loss: 0.3184 - val_acc: 0.9131\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3337 - acc: 0.9085 - val_loss: 0.3090 - val_acc: 0.9162\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3235 - acc: 0.9107 - val_loss: 0.3006 - val_acc: 0.9174\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3147 - acc: 0.9136 - val_loss: 0.2935 - val_acc: 0.9192\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3067 - acc: 0.9153 - val_loss: 0.2871 - val_acc: 0.9205\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2996 - acc: 0.9173 - val_loss: 0.2812 - val_acc: 0.9227\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2929 - acc: 0.9190 - val_loss: 0.2760 - val_acc: 0.9234\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2868 - acc: 0.9212 - val_loss: 0.2710 - val_acc: 0.9252\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2811 - acc: 0.9225 - val_loss: 0.2660 - val_acc: 0.9262\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2758 - acc: 0.9243 - val_loss: 0.2619 - val_acc: 0.9272\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2708 - acc: 0.9250 - val_loss: 0.2579 - val_acc: 0.9279\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2661 - acc: 0.9266 - val_loss: 0.2539 - val_acc: 0.9294\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2616 - acc: 0.9277 - val_loss: 0.2501 - val_acc: 0.9304\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2574 - acc: 0.9288 - val_loss: 0.2463 - val_acc: 0.9320\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2533 - acc: 0.9301 - val_loss: 0.2430 - val_acc: 0.9322\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2494 - acc: 0.9311 - val_loss: 0.2396 - val_acc: 0.9340\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2455 - acc: 0.9323 - val_loss: 0.2367 - val_acc: 0.9348\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2420 - acc: 0.9333 - val_loss: 0.2337 - val_acc: 0.9349\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2384 - acc: 0.9345 - val_loss: 0.2308 - val_acc: 0.9366\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2351 - acc: 0.9353 - val_loss: 0.2278 - val_acc: 0.9373\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2319 - acc: 0.9360 - val_loss: 0.2251 - val_acc: 0.9382\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2287 - acc: 0.9373 - val_loss: 0.2233 - val_acc: 0.9390\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2257 - acc: 0.9378 - val_loss: 0.2201 - val_acc: 0.9401\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2227 - acc: 0.9387 - val_loss: 0.2179 - val_acc: 0.9404\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2197 - acc: 0.9397 - val_loss: 0.2153 - val_acc: 0.9407\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2171 - acc: 0.9402 - val_loss: 0.2130 - val_acc: 0.9417\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2143 - acc: 0.9412 - val_loss: 0.2108 - val_acc: 0.9427\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2117 - acc: 0.9420 - val_loss: 0.2086 - val_acc: 0.9437\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2091 - acc: 0.9422 - val_loss: 0.2064 - val_acc: 0.9446\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2066 - acc: 0.9434 - val_loss: 0.2043 - val_acc: 0.9447\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2041 - acc: 0.9440 - val_loss: 0.2023 - val_acc: 0.9455\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2018 - acc: 0.9444 - val_loss: 0.2002 - val_acc: 0.9467\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1994 - acc: 0.9449 - val_loss: 0.1986 - val_acc: 0.9461\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1971 - acc: 0.9455 - val_loss: 0.1965 - val_acc: 0.9472\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1949 - acc: 0.9459 - val_loss: 0.1946 - val_acc: 0.9478\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1928 - acc: 0.9465 - val_loss: 0.1929 - val_acc: 0.9476\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1906 - acc: 0.9471 - val_loss: 0.1913 - val_acc: 0.9487\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1885 - acc: 0.9480 - val_loss: 0.1896 - val_acc: 0.9493\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1865 - acc: 0.9480 - val_loss: 0.1877 - val_acc: 0.9498\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1844 - acc: 0.9490 - val_loss: 0.1860 - val_acc: 0.9504\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1825 - acc: 0.9492 - val_loss: 0.1844 - val_acc: 0.9506\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1806 - acc: 0.9500 - val_loss: 0.1829 - val_acc: 0.9514\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1786 - acc: 0.9502 - val_loss: 0.1814 - val_acc: 0.9511\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1769 - acc: 0.9509 - val_loss: 0.1797 - val_acc: 0.9522\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1750 - acc: 0.9514 - val_loss: 0.1786 - val_acc: 0.9522\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1732 - acc: 0.9519 - val_loss: 0.1769 - val_acc: 0.9529\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1715 - acc: 0.9524 - val_loss: 0.1757 - val_acc: 0.9532\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1697 - acc: 0.9528 - val_loss: 0.1740 - val_acc: 0.9533\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1681 - acc: 0.9532 - val_loss: 0.1727 - val_acc: 0.9540\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1664 - acc: 0.9536 - val_loss: 0.1715 - val_acc: 0.9540\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1648 - acc: 0.9541 - val_loss: 0.1700 - val_acc: 0.9542\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1632 - acc: 0.9547 - val_loss: 0.1688 - val_acc: 0.9543\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1616 - acc: 0.9546 - val_loss: 0.1675 - val_acc: 0.9549\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1600 - acc: 0.9554 - val_loss: 0.1664 - val_acc: 0.9551\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1585 - acc: 0.9559 - val_loss: 0.1654 - val_acc: 0.9551\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1570 - acc: 0.9561 - val_loss: 0.1641 - val_acc: 0.9552\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1556 - acc: 0.9565 - val_loss: 0.1629 - val_acc: 0.9559\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1542 - acc: 0.9572 - val_loss: 0.1616 - val_acc: 0.9563\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1527 - acc: 0.9574 - val_loss: 0.1604 - val_acc: 0.9563\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1514 - acc: 0.9581 - val_loss: 0.1595 - val_acc: 0.9567\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1500 - acc: 0.9588 - val_loss: 0.1583 - val_acc: 0.9571\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1487 - acc: 0.9590 - val_loss: 0.1573 - val_acc: 0.9577\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1473 - acc: 0.9597 - val_loss: 0.1564 - val_acc: 0.9578\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1460 - acc: 0.9601 - val_loss: 0.1553 - val_acc: 0.9580\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1447 - acc: 0.9604 - val_loss: 0.1543 - val_acc: 0.9584\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1435 - acc: 0.9608 - val_loss: 0.1532 - val_acc: 0.9583\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1422 - acc: 0.9615 - val_loss: 0.1523 - val_acc: 0.9586\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1410 - acc: 0.9617 - val_loss: 0.1515 - val_acc: 0.9588\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1397 - acc: 0.9623 - val_loss: 0.1505 - val_acc: 0.9593\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1386 - acc: 0.9624 - val_loss: 0.1495 - val_acc: 0.9597\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1374 - acc: 0.9627 - val_loss: 0.1485 - val_acc: 0.9600\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1363 - acc: 0.9631 - val_loss: 0.1478 - val_acc: 0.9599\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1352 - acc: 0.9635 - val_loss: 0.1468 - val_acc: 0.9600\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1340 - acc: 0.9637 - val_loss: 0.1459 - val_acc: 0.9608\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1329 - acc: 0.9641 - val_loss: 0.1452 - val_acc: 0.9609\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1318 - acc: 0.9642 - val_loss: 0.1444 - val_acc: 0.9617\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1308 - acc: 0.9649 - val_loss: 0.1434 - val_acc: 0.9614\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1297 - acc: 0.9649 - val_loss: 0.1426 - val_acc: 0.9614\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1287 - acc: 0.9655 - val_loss: 0.1420 - val_acc: 0.9618\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1277 - acc: 0.9654 - val_loss: 0.1410 - val_acc: 0.9624\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1267 - acc: 0.9658 - val_loss: 0.1403 - val_acc: 0.9617\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1257 - acc: 0.9663 - val_loss: 0.1396 - val_acc: 0.9624\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1247 - acc: 0.9664 - val_loss: 0.1389 - val_acc: 0.9626\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1237 - acc: 0.9665 - val_loss: 0.1383 - val_acc: 0.9624\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1228 - acc: 0.9667 - val_loss: 0.1373 - val_acc: 0.9632\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1219 - acc: 0.9672 - val_loss: 0.1368 - val_acc: 0.9630\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1209 - acc: 0.9677 - val_loss: 0.1362 - val_acc: 0.9633\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1200 - acc: 0.9677 - val_loss: 0.1355 - val_acc: 0.9628\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1191 - acc: 0.9679 - val_loss: 0.1346 - val_acc: 0.9636\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1182 - acc: 0.9681 - val_loss: 0.1340 - val_acc: 0.9634\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1174 - acc: 0.9683 - val_loss: 0.1333 - val_acc: 0.9638\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1165 - acc: 0.9686 - val_loss: 0.1327 - val_acc: 0.9638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b4eb6ebe0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 200, epochs = 100, validation_split = 0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка качества сети на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12783813556879758, 0.9626]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test/255\n",
    "y_test = utils.to_categorical(y_test,10)\n",
    "\n",
    "model.evaluate(x_test,y_test, verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим другую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(800,input_dim = 784, activation =\"relu\"))\n",
    "model_1.add(Dense(10, activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 636,010\n",
      "Trainable params: 636,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss = \"mean_squared_error\", optimizer =\"SGD\", metrics =[\"accuracy\"] )\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0898 - acc: 0.1596 - val_loss: 0.0890 - val_acc: 0.2006\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0880 - acc: 0.2370 - val_loss: 0.0872 - val_acc: 0.2689\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0861 - acc: 0.2917 - val_loss: 0.0852 - val_acc: 0.3209\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0841 - acc: 0.3417 - val_loss: 0.0830 - val_acc: 0.3687\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0820 - acc: 0.3883 - val_loss: 0.0808 - val_acc: 0.4202\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0798 - acc: 0.4381 - val_loss: 0.0785 - val_acc: 0.4643\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0775 - acc: 0.4786 - val_loss: 0.0762 - val_acc: 0.5023\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0752 - acc: 0.5116 - val_loss: 0.0738 - val_acc: 0.5309\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0728 - acc: 0.5358 - val_loss: 0.0713 - val_acc: 0.5567\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0704 - acc: 0.5572 - val_loss: 0.0689 - val_acc: 0.5790\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0680 - acc: 0.5784 - val_loss: 0.0664 - val_acc: 0.6038\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0657 - acc: 0.6012 - val_loss: 0.0640 - val_acc: 0.6288\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0635 - acc: 0.6238 - val_loss: 0.0617 - val_acc: 0.6510\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0613 - acc: 0.6450 - val_loss: 0.0595 - val_acc: 0.6749\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0592 - acc: 0.6648 - val_loss: 0.0573 - val_acc: 0.6925\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0572 - acc: 0.6834 - val_loss: 0.0553 - val_acc: 0.7097\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0552 - acc: 0.6997 - val_loss: 0.0533 - val_acc: 0.7261\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0534 - acc: 0.7137 - val_loss: 0.0515 - val_acc: 0.7380\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0517 - acc: 0.7274 - val_loss: 0.0497 - val_acc: 0.7476\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0501 - acc: 0.7396 - val_loss: 0.0481 - val_acc: 0.7573\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0485 - acc: 0.7497 - val_loss: 0.0466 - val_acc: 0.7641\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0471 - acc: 0.7579 - val_loss: 0.0451 - val_acc: 0.7724\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0458 - acc: 0.7636 - val_loss: 0.0438 - val_acc: 0.7759\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0445 - acc: 0.7683 - val_loss: 0.0425 - val_acc: 0.7802\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0433 - acc: 0.7729 - val_loss: 0.0413 - val_acc: 0.7843\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0422 - acc: 0.7770 - val_loss: 0.0401 - val_acc: 0.7886\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0411 - acc: 0.7812 - val_loss: 0.0390 - val_acc: 0.7926\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0400 - acc: 0.7875 - val_loss: 0.0380 - val_acc: 0.8008\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0390 - acc: 0.7955 - val_loss: 0.0369 - val_acc: 0.8089\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0381 - acc: 0.8045 - val_loss: 0.0360 - val_acc: 0.8172\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0371 - acc: 0.8134 - val_loss: 0.0350 - val_acc: 0.8258\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0363 - acc: 0.8204 - val_loss: 0.0341 - val_acc: 0.8331\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0354 - acc: 0.8255 - val_loss: 0.0333 - val_acc: 0.8396\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0346 - acc: 0.8306 - val_loss: 0.0325 - val_acc: 0.8429\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0339 - acc: 0.8345 - val_loss: 0.0318 - val_acc: 0.8477\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0332 - acc: 0.8373 - val_loss: 0.0311 - val_acc: 0.8513\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0325 - acc: 0.8402 - val_loss: 0.0304 - val_acc: 0.8529\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0319 - acc: 0.8427 - val_loss: 0.0298 - val_acc: 0.8553\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0313 - acc: 0.8450 - val_loss: 0.0293 - val_acc: 0.8580\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0308 - acc: 0.8471 - val_loss: 0.0287 - val_acc: 0.8600\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0303 - acc: 0.8491 - val_loss: 0.0282 - val_acc: 0.8618\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0298 - acc: 0.8506 - val_loss: 0.0277 - val_acc: 0.8646\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0293 - acc: 0.8522 - val_loss: 0.0273 - val_acc: 0.8660\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0289 - acc: 0.8536 - val_loss: 0.0268 - val_acc: 0.8671\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0284 - acc: 0.8549 - val_loss: 0.0264 - val_acc: 0.8684\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0280 - acc: 0.8559 - val_loss: 0.0260 - val_acc: 0.8700\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0276 - acc: 0.8573 - val_loss: 0.0257 - val_acc: 0.8713\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0273 - acc: 0.8586 - val_loss: 0.0253 - val_acc: 0.8726\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0269 - acc: 0.8598 - val_loss: 0.0250 - val_acc: 0.8733\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0266 - acc: 0.8611 - val_loss: 0.0247 - val_acc: 0.8741\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0263 - acc: 0.8621 - val_loss: 0.0244 - val_acc: 0.8750\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0260 - acc: 0.8630 - val_loss: 0.0241 - val_acc: 0.8761\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0257 - acc: 0.8642 - val_loss: 0.0238 - val_acc: 0.8764\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0254 - acc: 0.8653 - val_loss: 0.0235 - val_acc: 0.8774\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0252 - acc: 0.8665 - val_loss: 0.0233 - val_acc: 0.8778\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0249 - acc: 0.8674 - val_loss: 0.0230 - val_acc: 0.8780\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0246 - acc: 0.8683 - val_loss: 0.0228 - val_acc: 0.8787\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0244 - acc: 0.8689 - val_loss: 0.0226 - val_acc: 0.8798\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0242 - acc: 0.8699 - val_loss: 0.0224 - val_acc: 0.8804\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0240 - acc: 0.8705 - val_loss: 0.0221 - val_acc: 0.8814\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0237 - acc: 0.8715 - val_loss: 0.0219 - val_acc: 0.8821\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0235 - acc: 0.8724 - val_loss: 0.0218 - val_acc: 0.8830\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0233 - acc: 0.8731 - val_loss: 0.0216 - val_acc: 0.8836\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0232 - acc: 0.8738 - val_loss: 0.0214 - val_acc: 0.8840\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0230 - acc: 0.8745 - val_loss: 0.0212 - val_acc: 0.8849\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0228 - acc: 0.8751 - val_loss: 0.0210 - val_acc: 0.8856\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0226 - acc: 0.8760 - val_loss: 0.0209 - val_acc: 0.8857\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0224 - acc: 0.8765 - val_loss: 0.0207 - val_acc: 0.8863\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0223 - acc: 0.8774 - val_loss: 0.0206 - val_acc: 0.8869\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0221 - acc: 0.8779 - val_loss: 0.0204 - val_acc: 0.8874\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0220 - acc: 0.8785 - val_loss: 0.0203 - val_acc: 0.8884\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0218 - acc: 0.8791 - val_loss: 0.0201 - val_acc: 0.8887\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0217 - acc: 0.8798 - val_loss: 0.0200 - val_acc: 0.8892\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0215 - acc: 0.8801 - val_loss: 0.0199 - val_acc: 0.8896\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0214 - acc: 0.8807 - val_loss: 0.0197 - val_acc: 0.8902\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0213 - acc: 0.8810 - val_loss: 0.0196 - val_acc: 0.8907\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0211 - acc: 0.8815 - val_loss: 0.0195 - val_acc: 0.8907\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0210 - acc: 0.8820 - val_loss: 0.0194 - val_acc: 0.8909\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0209 - acc: 0.8822 - val_loss: 0.0193 - val_acc: 0.8911\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0208 - acc: 0.8828 - val_loss: 0.0192 - val_acc: 0.8918\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0207 - acc: 0.8834 - val_loss: 0.0191 - val_acc: 0.8929\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0205 - acc: 0.8836 - val_loss: 0.0189 - val_acc: 0.8929\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0204 - acc: 0.8844 - val_loss: 0.0188 - val_acc: 0.8934\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0203 - acc: 0.8850 - val_loss: 0.0187 - val_acc: 0.8937\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0202 - acc: 0.8851 - val_loss: 0.0186 - val_acc: 0.8945\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0201 - acc: 0.8860 - val_loss: 0.0185 - val_acc: 0.8952\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0200 - acc: 0.8862 - val_loss: 0.0185 - val_acc: 0.8954\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0199 - acc: 0.8866 - val_loss: 0.0184 - val_acc: 0.8959\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0198 - acc: 0.8871 - val_loss: 0.0183 - val_acc: 0.8966\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0197 - acc: 0.8876 - val_loss: 0.0182 - val_acc: 0.8971\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0196 - acc: 0.8879 - val_loss: 0.0181 - val_acc: 0.8974\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0195 - acc: 0.8882 - val_loss: 0.0180 - val_acc: 0.8979\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0194 - acc: 0.8887 - val_loss: 0.0179 - val_acc: 0.8983\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0194 - acc: 0.8890 - val_loss: 0.0179 - val_acc: 0.8989\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0193 - acc: 0.8894 - val_loss: 0.0178 - val_acc: 0.8994\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0192 - acc: 0.8897 - val_loss: 0.0177 - val_acc: 0.8995\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0191 - acc: 0.8898 - val_loss: 0.0176 - val_acc: 0.8998\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0190 - acc: 0.8901 - val_loss: 0.0176 - val_acc: 0.9002\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0189 - acc: 0.8905 - val_loss: 0.0175 - val_acc: 0.9002\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0189 - acc: 0.8909 - val_loss: 0.0174 - val_acc: 0.9007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b4f0c2908>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train, y_train, batch_size = 200, epochs = 100, validation_split = 0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.017608013186976315, 0.9004]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(x_test,y_test, verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим другую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(800,input_dim = 784, activation =\"relu\"))\n",
    "model_2.add(Dense(800, activation =\"relu\"))\n",
    "model_2.add(Dense(10, activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 800)               640800    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 1,276,810\n",
      "Trainable params: 1,276,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss = \"categorical_crossentropy\", optimizer =\"SGD\", metrics =[\"accuracy\"] )\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 1.4477 - acc: 0.6940 - val_loss: 0.8011 - val_acc: 0.8464\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.6450 - acc: 0.8533 - val_loss: 0.4896 - val_acc: 0.8812\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.4699 - acc: 0.8811 - val_loss: 0.3969 - val_acc: 0.8954\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.4008 - acc: 0.8932 - val_loss: 0.3522 - val_acc: 0.9054\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3623 - acc: 0.9015 - val_loss: 0.3253 - val_acc: 0.9102\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3366 - acc: 0.9071 - val_loss: 0.3061 - val_acc: 0.9143\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3175 - acc: 0.9118 - val_loss: 0.2922 - val_acc: 0.9170\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3024 - acc: 0.9157 - val_loss: 0.2813 - val_acc: 0.9213\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2901 - acc: 0.9184 - val_loss: 0.2697 - val_acc: 0.9233\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2789 - acc: 0.9217 - val_loss: 0.2607 - val_acc: 0.9264\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2694 - acc: 0.9243 - val_loss: 0.2538 - val_acc: 0.9288\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2606 - acc: 0.9272 - val_loss: 0.2468 - val_acc: 0.9312\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2526 - acc: 0.9290 - val_loss: 0.2400 - val_acc: 0.9330\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2451 - acc: 0.9309 - val_loss: 0.2345 - val_acc: 0.9342\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2385 - acc: 0.9327 - val_loss: 0.2282 - val_acc: 0.9369\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2318 - acc: 0.9348 - val_loss: 0.2231 - val_acc: 0.9386\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2259 - acc: 0.9368 - val_loss: 0.2182 - val_acc: 0.9388\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2204 - acc: 0.9378 - val_loss: 0.2133 - val_acc: 0.9403\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2149 - acc: 0.9397 - val_loss: 0.2089 - val_acc: 0.9423\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.2096 - acc: 0.9405 - val_loss: 0.2049 - val_acc: 0.9426\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2048 - acc: 0.9415 - val_loss: 0.2011 - val_acc: 0.9444\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2000 - acc: 0.9436 - val_loss: 0.1972 - val_acc: 0.9459\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1958 - acc: 0.9451 - val_loss: 0.1934 - val_acc: 0.9479\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1914 - acc: 0.9457 - val_loss: 0.1897 - val_acc: 0.9489\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1873 - acc: 0.9477 - val_loss: 0.1879 - val_acc: 0.9495\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1833 - acc: 0.9482 - val_loss: 0.1836 - val_acc: 0.9506\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1794 - acc: 0.9496 - val_loss: 0.1809 - val_acc: 0.9507\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1758 - acc: 0.9502 - val_loss: 0.1781 - val_acc: 0.9517\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1723 - acc: 0.9518 - val_loss: 0.1751 - val_acc: 0.9529\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.1688 - acc: 0.9530 - val_loss: 0.1721 - val_acc: 0.9528\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1655 - acc: 0.9534 - val_loss: 0.1696 - val_acc: 0.9535\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1623 - acc: 0.9546 - val_loss: 0.1676 - val_acc: 0.9542\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1591 - acc: 0.9556 - val_loss: 0.1648 - val_acc: 0.9552\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1562 - acc: 0.9567 - val_loss: 0.1623 - val_acc: 0.9561\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1532 - acc: 0.9578 - val_loss: 0.1603 - val_acc: 0.9568\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1504 - acc: 0.9581 - val_loss: 0.1581 - val_acc: 0.9570\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1477 - acc: 0.9586 - val_loss: 0.1561 - val_acc: 0.9574\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1452 - acc: 0.9596 - val_loss: 0.1537 - val_acc: 0.9584\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.1423 - acc: 0.9604 - val_loss: 0.1519 - val_acc: 0.9595\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.1400 - acc: 0.9616 - val_loss: 0.1504 - val_acc: 0.9597\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1375 - acc: 0.9616 - val_loss: 0.1484 - val_acc: 0.9600\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1351 - acc: 0.9624 - val_loss: 0.1469 - val_acc: 0.9599\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.1328 - acc: 0.9631 - val_loss: 0.1452 - val_acc: 0.9604\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.1306 - acc: 0.9640 - val_loss: 0.1435 - val_acc: 0.9616\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1285 - acc: 0.9643 - val_loss: 0.1421 - val_acc: 0.9613\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1266 - acc: 0.9645 - val_loss: 0.1399 - val_acc: 0.9616\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1244 - acc: 0.9651 - val_loss: 0.1386 - val_acc: 0.9623\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1221 - acc: 0.9658 - val_loss: 0.1375 - val_acc: 0.9628\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1205 - acc: 0.9668 - val_loss: 0.1358 - val_acc: 0.9626\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1184 - acc: 0.9673 - val_loss: 0.1347 - val_acc: 0.9636\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1166 - acc: 0.9678 - val_loss: 0.1332 - val_acc: 0.9627\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.1147 - acc: 0.9685 - val_loss: 0.1330 - val_acc: 0.9628\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.1129 - acc: 0.9693 - val_loss: 0.1309 - val_acc: 0.9642\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1112 - acc: 0.9697 - val_loss: 0.1293 - val_acc: 0.9649\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1096 - acc: 0.9700 - val_loss: 0.1282 - val_acc: 0.9646\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.1078 - acc: 0.9705 - val_loss: 0.1273 - val_acc: 0.9657\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1064 - acc: 0.9713 - val_loss: 0.1261 - val_acc: 0.9644\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1046 - acc: 0.9718 - val_loss: 0.1250 - val_acc: 0.9659\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1031 - acc: 0.9719 - val_loss: 0.1245 - val_acc: 0.9652\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.1016 - acc: 0.9724 - val_loss: 0.1228 - val_acc: 0.9653\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1001 - acc: 0.9733 - val_loss: 0.1221 - val_acc: 0.9660\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.0987 - acc: 0.9733 - val_loss: 0.1212 - val_acc: 0.9664\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0973 - acc: 0.9743 - val_loss: 0.1207 - val_acc: 0.9672\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0960 - acc: 0.9744 - val_loss: 0.1196 - val_acc: 0.9664\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0946 - acc: 0.9746 - val_loss: 0.1181 - val_acc: 0.9672\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0933 - acc: 0.9747 - val_loss: 0.1180 - val_acc: 0.9675\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0920 - acc: 0.9755 - val_loss: 0.1170 - val_acc: 0.9679\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0907 - acc: 0.9760 - val_loss: 0.1158 - val_acc: 0.9678\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0895 - acc: 0.9762 - val_loss: 0.1150 - val_acc: 0.9683\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0882 - acc: 0.9766 - val_loss: 0.1138 - val_acc: 0.9683\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0871 - acc: 0.9769 - val_loss: 0.1137 - val_acc: 0.9685\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0858 - acc: 0.9772 - val_loss: 0.1136 - val_acc: 0.9683\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0848 - acc: 0.9777 - val_loss: 0.1118 - val_acc: 0.9688\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0836 - acc: 0.9779 - val_loss: 0.1115 - val_acc: 0.9683\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0824 - acc: 0.9784 - val_loss: 0.1106 - val_acc: 0.9684\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0813 - acc: 0.9784 - val_loss: 0.1100 - val_acc: 0.9680\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0802 - acc: 0.9789 - val_loss: 0.1090 - val_acc: 0.9689\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0791 - acc: 0.9796 - val_loss: 0.1086 - val_acc: 0.9694\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0782 - acc: 0.9794 - val_loss: 0.1073 - val_acc: 0.9693\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0771 - acc: 0.9798 - val_loss: 0.1075 - val_acc: 0.9684\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0762 - acc: 0.9801 - val_loss: 0.1062 - val_acc: 0.9697\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0752 - acc: 0.9804 - val_loss: 0.1059 - val_acc: 0.9700\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0742 - acc: 0.9806 - val_loss: 0.1058 - val_acc: 0.9695\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0733 - acc: 0.9810 - val_loss: 0.1047 - val_acc: 0.9699\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0724 - acc: 0.9811 - val_loss: 0.1043 - val_acc: 0.9706\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0714 - acc: 0.9817 - val_loss: 0.1038 - val_acc: 0.9705\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0706 - acc: 0.9816 - val_loss: 0.1031 - val_acc: 0.9700\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0697 - acc: 0.9821 - val_loss: 0.1029 - val_acc: 0.9700\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0688 - acc: 0.9820 - val_loss: 0.1024 - val_acc: 0.9701\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0679 - acc: 0.9824 - val_loss: 0.1017 - val_acc: 0.9710\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0671 - acc: 0.9825 - val_loss: 0.1017 - val_acc: 0.9701\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0663 - acc: 0.9829 - val_loss: 0.1002 - val_acc: 0.9702\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0655 - acc: 0.9836 - val_loss: 0.0998 - val_acc: 0.9709\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0648 - acc: 0.9833 - val_loss: 0.0995 - val_acc: 0.9709\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0640 - acc: 0.9836 - val_loss: 0.0993 - val_acc: 0.9704\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0631 - acc: 0.9839 - val_loss: 0.0991 - val_acc: 0.9708\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0625 - acc: 0.9840 - val_loss: 0.0988 - val_acc: 0.9707\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0616 - acc: 0.9844 - val_loss: 0.0976 - val_acc: 0.9711\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0607 - acc: 0.9848 - val_loss: 0.0981 - val_acc: 0.9713\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0601 - acc: 0.9851 - val_loss: 0.0980 - val_acc: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b4eb76b70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train, batch_size = 200, epochs = 100, validation_split = 0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09140263799186796, 0.9727]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(x_test,y_test, verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем на фото"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img('5.jpg', target_size = (28,28), color_mode = \"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image.img_to_array(img)\n",
    "X = X.reshape(1,784)\n",
    "# Инвертируем\n",
    "X = 255 - X \n",
    "X = X /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8115563e-07 3.1745717e-09 3.7186690e-10 3.3832552e-05 3.3334932e-11\n",
      "  9.9991345e-01 1.3485980e-08 5.9782890e-12 2.1852978e-07 5.2290055e-05]]\n",
      "result:  5\n"
     ]
    }
   ],
   "source": [
    "prediction = model_2.predict(X)\n",
    "\n",
    "print(prediction)\n",
    "print('result: ', np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.savw('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
